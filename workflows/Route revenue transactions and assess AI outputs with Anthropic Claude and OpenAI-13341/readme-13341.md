Route revenue transactions and assess AI outputs with Anthropic Claude and OpenAI

https://n8nworkflows.xyz/workflows/route-revenue-transactions-and-assess-ai-outputs-with-anthropic-claude-and-openai-13341


# Route revenue transactions and assess AI outputs with Anthropic Claude and OpenAI

disclaimer Le texte fourni provient exclusivement d’un workflow automatisé réalisé avec n8n, un outil d’intégration et d’automatisation. Ce traitement respecte strictement les politiques de contenu en vigueur et ne contient aucun élément illégal, offensant ou protégé. Toutes les données manipulées sont légales et publiques.

## 1. Workflow Overview

**Purpose:** This workflow simulates a revenue-transaction governance pipeline that (1) generates sample revenue transactions, (2) validates each transaction with an AI “Revenue Signal Agent”, (3) routes only valid items into a multi-tool “Governance Agent” that calculates payouts, checks compliance, assesses risk, and calculates taxes, (4) routes outcomes by risk level into storage tables, and (5) aggregates everything into an executive report generated by a “Reporting Agent”.

**Target use cases:** monetization operations, partner payout governance, compliance/risk triage, and operational reporting. Sticky notes also mention “query routing and model selection” and “OpenAI”, but **this specific JSON uses only Anthropic Claude models**; there are **no OpenAI nodes**.

### Logical blocks
1.1 **Scheduling & Configuration** → Trigger and set global thresholds/rates.  
1.2 **Data Generation (Sample Transactions)** → Produces multiple transactions (one item per transaction).  
1.3 **AI Validation (Revenue Signal Validation)** → Claude agent validates structure/quality and outputs a structured status/score.  
1.4 **Routing by Validation Status** → Valid items continue; invalid/suspicious items are stored as failed validations.  
1.5 **Governance Orchestration (AI Tool-Calling Agent)** → Claude governance agent calls tools: payout, compliance, risk, and tax code tool; outputs structured governance decision including risk level.  
1.6 **Routing by Risk + Storage** → Low/medium vs high/critical routed to separate tables.  
1.7 **Merge, Aggregate, and Reporting** → Merge all storage outputs, aggregate, generate final report, store report.

---

## 2. Block-by-Block Analysis

### 2.1 Scheduling & Configuration
**Overview:** Starts the workflow on a schedule and sets shared constants (thresholds and rates) intended for downstream decisions/tools.  
**Nodes involved:** `Schedule Trigger`, `Workflow Configuration`

#### Schedule Trigger
- **Type / role:** `n8n-nodes-base.scheduleTrigger` — entry point.
- **Configuration:** Runs at **09:00** (based on `triggerAtHour: 9`; no minutes specified).
- **Outputs:** To `Workflow Configuration`.
- **Edge cases / failures:**
  - Timezone depends on n8n instance settings; can lead to unexpected run times.
  - If you expect multiple runs/day, current rule won’t do that.

#### Workflow Configuration
- **Type / role:** `n8n-nodes-base.set` — injects config fields into each item.
- **Configuration choices:**
  - Adds numeric/string fields:
    - `revenueThreshold: 10000`
    - `highRiskThreshold: 50000`
    - `complianceRegion: "US"`
    - `taxRate: 0.21`
    - `payoutCommissionRate: 0.15`
  - `includeOtherFields: true` keeps incoming fields (though at this point the trigger produces an empty item).
- **Outputs:** To `Generate Sample Revenue Data`.
- **Edge cases / failures:**
  - Downstream tools/agents do not consistently reference these config fields (they mainly rely on AI reasoning or hard-coded tax rates in the tax tool). If you expect deterministic behavior, you must wire these values into prompts/tool code explicitly.

**Sticky note context (applies to this block and nearby):**
- “## Query Classification … Determines optimal routing path and appropriate model selection.”
- “## How It Works … intelligent routing … validates outputs … stores flagged responses …”
- “## Setup Steps … Connect Anthropic and OpenAI … Google Sheets … Slack/Gmail …” (but this workflow uses Data Tables, and no OpenAI/Slack/Gmail nodes exist here).

---

### 2.2 Data Generation (Sample Transactions)
**Overview:** Creates a batch of 5 example revenue transactions for testing, emitting one n8n item per transaction.  
**Nodes involved:** `Generate Sample Revenue Data`

#### Generate Sample Revenue Data
- **Type / role:** `n8n-nodes-base.code` — generates synthetic data.
- **Configuration choices:**
  - Returns 5 transactions with fields such as:
    - `transactionId`, `partnerId`, `partnerName`
    - `revenueAmount` (varies: 5200–45000)
    - `engagementMetrics` (`clicks`, `conversions`, `impressions`)
    - `timestamp` (ISO strings, staggered)
    - `channel`, `region`, `status: "pending"`
  - Returns `transactions.map(transaction => ({ json: transaction }))` (one item per transaction).
- **Outputs:** To `Revenue Signal Agent`.
- **Edge cases / failures:**
  - This is sample-only; replacing with real ingestion requires schema alignment with the validation agent expectations.
  - If you later add config from `Workflow Configuration`, note it’s not merged here (this node overwrites the item JSON entirely). You’d need to copy config fields in or merge streams.

**Sticky note context:** “Query Classification …” (conceptually this is where real incoming items would be classified).

---

### 2.3 AI Validation (Revenue Signal Validation)
**Overview:** Uses a Claude-powered agent to validate each transaction’s schema and plausibility, detect anomalies, and output a structured validation result.  
**Nodes involved:** `Revenue Signal Agent`, `Anthropic Model - Revenue Agent`, `Revenue Validation Output Parser`

#### Revenue Signal Agent
- **Type / role:** `@n8n/n8n-nodes-langchain.agent` — orchestrates LLM reasoning and produces structured output via parser.
- **Key configuration:**
  - **Input text:** `{{ JSON.stringify($json) }}` (the full transaction JSON).
  - **System message:** Detailed instructions to validate required fields, data quality, anomalies, compute `engagementQualityScore`, and set `validationStatus` (`VALID/INVALID/SUSPICIOUS`).
  - **hasOutputParser:** enabled (expects structured output).
- **Connections:**
  - **Language model:** `Anthropic Model - Revenue Agent` via `ai_languageModel`.
  - **Output parser:** `Revenue Validation Output Parser` via `ai_outputParser`.
  - **Main output:** to `Route by Validation Status`.
- **Edge cases / failures:**
  - Parser failures if the model returns non-JSON or schema-mismatched JSON.
  - The agent can hallucinate “duplicate transactions” without a global view; it only sees one transaction at a time.
  - Engagement quality scoring isn’t enforced mathematically—relies on model judgment.

#### Anthropic Model - Revenue Agent
- **Type / role:** `lmChatAnthropic` — Claude chat model for the validation agent.
- **Configuration:** Model set to `claude-sonnet-4-5-20250929`.
- **Credentials:** `Anthropic account`.
- **Edge cases / failures:** API auth errors, rate limits, model name availability, latency/timeouts.

#### Revenue Validation Output Parser
- **Type / role:** `outputParserStructured` — validates/forces structured JSON output.
- **Schema highlights (required):**
  - Required: `transactionId`, `validationStatus`, `engagementQualityScore`, `reasoning`
  - Optional: `anomaliesDetected[]`, `originalData` object
- **Connections:** Attached to `Revenue Signal Agent` as its output parser.
- **Edge cases / failures:**
  - If `validationStatus` values differ (e.g., “Valid” instead of “VALID”), downstream routing will misclassify.
  - Missing `engagementQualityScore` causes parsing failure because it is not listed as required in JSON schema? (In this schema it is **not** in `required`, but it is defined; downstream might still assume it exists.)

**Sticky note context:** “Model-Specific Agents … Anthropic and OpenAI …” (in practice: Anthropic only).

---

### 2.4 Routing by Validation Status + Failed Validation Storage
**Overview:** Routes validated items: VALID proceeds to governance; INVALID/SUSPICIOUS are stored for review.  
**Nodes involved:** `Route by Validation Status`, `Store Failed Validations`

#### Route by Validation Status
- **Type / role:** `n8n-nodes-base.switch` — conditional routing.
- **Rules:**
  - Output **“Valid”** if `{{$json.validationStatus}} == "VALID"`
  - Output **“Invalid”** if `validationStatus == "INVALID"` OR `"SUSPICIOUS"`
  - Fallback output renamed to **“Unprocessed”**
- **Connections:**
  - **Valid** → `Governance Agent`
  - **Invalid** → `Store Failed Validations`
- **Edge cases / failures:**
  - Case sensitivity is enforced; any deviation (e.g., lowercase) routes to fallback.
  - If the parser output nests fields differently, `$json.validationStatus` may not exist.

#### Store Failed Validations
- **Type / role:** `n8n-nodes-base.dataTable` — persists failed/suspicious validation outputs.
- **Configuration:** Writes to data table named `failed_validations`.
- **Output:** To `Merge Storage Results` (input index 2).
- **Edge cases / failures:**
  - Data Table not created or permission issues.
  - Schema drift: Data Tables in n8n accept flexible JSON, but downstream aggregation may become inconsistent if item shapes differ widely.

---

### 2.5 Governance Orchestration (Tool-Calling Agent)
**Overview:** For validated transactions, a governance agent coordinates multiple specialized tools (payout, compliance, risk, tax) and emits a consolidated governance decision including `riskLevel` used for subsequent routing.  
**Nodes involved:**  
`Governance Agent`, `Anthropic Model - Governance Agent`, `Governance Output Parser`,  
`Payout Calculation Agent Tool`, `Anthropic Model - Payout Tool`, `Payout Output Parser`,  
`Compliance Check Agent Tool`, `Anthropic Model - Compliance Tool`, `Compliance Output Parser`,  
`Risk Assessment Agent Tool`, `Anthropic Model - Risk Tool`, `Risk Output Parser`,  
`Tax Calculation Tool`

#### Governance Agent
- **Type / role:** `@n8n/n8n-nodes-langchain.agent` — central orchestrator that calls tools.
- **Key configuration:**
  - **Input text:** `{{ JSON.stringify($json) }}` (validated transaction payload).
  - **System message:** Instructs agent to call tools systematically and return:
    - payouts, tax, compliance status, overall risk (`LOW/MEDIUM/HIGH/CRITICAL`), recommendations, approvalRequired
  - **hasOutputParser:** enabled.
- **Connections:**
  - **Language model:** `Anthropic Model - Governance Agent`
  - **Tools:** receives tool connections from:
    - `Payout Calculation Agent Tool` (ai_tool)
    - `Compliance Check Agent Tool` (ai_tool)
    - `Risk Assessment Agent Tool` (ai_tool)
    - `Tax Calculation Tool` (ai_tool)
  - **Output parser:** `Governance Output Parser`
  - **Main output:** to `Route by Risk Level`
- **Edge cases / failures:**
  - Tool-call argument mismatch: tools expect `$fromAI(...)` keys like `revenueData`/`transactionData`, but the governance agent must actually provide them consistently.
  - If any tool returns invalid JSON (or errors), the governance agent may still produce an output, but it could be inconsistent.
  - Determinism: payouts/tax could be model-driven unless forced by code (only tax is code-driven here).

#### Anthropic Model - Governance Agent
- **Type / role:** Claude model backing governance agent.
- **Configuration:** `claude-sonnet-4-5-20250929`.
- **Credentials:** Anthropic account.
- **Failures:** auth/rate-limits/timeouts.

#### Governance Output Parser
- **Type / role:** Structured output enforcement for governance result.
- **Required fields:** `transactionId`, `payoutAmount`, `complianceStatus`, `riskLevel`
- **Also defined:** `taxLiability`, `riskFactors[]`, `recommendations[]`, `approvalRequired`
- **Edge cases:**
  - If the governance agent only outputs tool raw results instead of mapping them into these required fields, parsing fails.

---

#### Payout Calculation Agent Tool
- **Type / role:** `agentTool` — tool callable by the governance agent; itself uses an LLM + parser.
- **Input mapping:** `{{ $fromAI("revenueData", "Revenue transaction data to calculate payouts", "json") }}`
- **System message:** instructs payout computation (commission, tiering, deductions).
- **Tool description:** “Calculates partner payout amounts…”
- **Connections:**
  - **Language model:** `Anthropic Model - Payout Tool`
  - **Output parser:** `Payout Output Parser`
  - **Tool connection:** to `Governance Agent` via `ai_tool`
- **Edge cases:**
  - The governance agent must pass `revenueData` in a compatible structure; otherwise the tool sees empty/incorrect input.
  - Commission rates from `Workflow Configuration` are not explicitly injected; the model may invent a rate unless you pass `payoutCommissionRate` in the tool input/prompt.

#### Anthropic Model - Payout Tool
- **Type / role:** Claude model for payout tool.
- **Configuration:** same Claude Sonnet 4.5 version.
- **Failures:** auth/rate limit.

#### Payout Output Parser
- **Schema (required):** `grossRevenue`, `commissionRate`, `netPayoutAmount`
- **Optional:** `deductions`
- **Edge cases:** numeric values may come back as strings; parser expects `number`.

---

#### Compliance Check Agent Tool
- **Type / role:** `agentTool` — compliance verification via LLM + parser.
- **Input mapping:** `{{ $fromAI("transactionData", "Transaction data to verify compliance", "json") }}`
- **System message:** regional regs, KYC/AML, thresholds; outputs `COMPLIANT/NON_COMPLIANT/REQUIRES_REVIEW`.
- **Connections:** Claude model + `Compliance Output Parser`, tool-connected to Governance Agent.
- **Edge cases:**
  - The workflow config `complianceRegion` is not enforced; the model may infer region from the transaction field `region` (which contains “Europe”, “North America”, etc., not “EU/US/APAC”).
  - Output status must match schema; governance parser later expects `complianceStatus` but only requires it; mismatch of naming/values can break routing/interpretation.

#### Anthropic Model - Compliance Tool
- Claude model.

#### Compliance Output Parser
- **Required:** `complianceStatus`
- **Optional arrays:** `violations[]`, `requiredActions[]`
- **Edge cases:** If the model outputs `COMPLIANT` etc. as lowercase, consumers may mis-handle.

---

#### Risk Assessment Agent Tool
- **Type / role:** `agentTool` — risk scoring via LLM + parser.
- **Input mapping:** `{{ $fromAI("transactionData", "Transaction data for risk assessment", "json") }}`
- **Outputs:** `riskScore (0-100)`, `riskLevel`, factors, mitigations, manual review flag.
- **Connections:** Claude model + `Risk Output Parser`, tool-connected to Governance Agent.
- **Edge cases:** risk levels must align with downstream switch: `LOW/MEDIUM/HIGH/CRITICAL`.

#### Anthropic Model - Risk Tool
- Claude model.

#### Risk Output Parser
- **Required:** `riskScore`, `riskLevel`
- **Optional:** `riskFactors[]`, `mitigationStrategies[]`, `requiresManualReview`
- **Edge cases:** Parser expects `number` riskScore; LLM may output `"85"` as string.

---

#### Tax Calculation Tool
- **Type / role:** `@n8n/n8n-nodes-langchain.toolCode` — deterministic code tool callable by governance agent.
- **Input mapping:** `const revenueData = $fromAI('revenueData', ..., 'json');`
- **Logic:**
  - Parses input; reads `revenueAmount` or `grossRevenue`.
  - Uses **hard-coded taxRates** mapping:
    - US 0.21, EU 0.25, UK 0.19, APAC 0.17 (default 0.21)
  - Computes `taxLiability` and `netRevenue`.
  - Returns a **stringified JSON** result.
- **Connections:** Tool-connected to `Governance Agent`.
- **Edge cases / failures:**
  - Returns **strings** for numeric fields (`toFixed(2)`), which can conflict if governance parser expects numbers.
  - Region mapping mismatch: transactions use “Europe”, “North America”, etc. Tax tool expects `US/EU/UK/APAC`. Default will be applied often.
  - It returns a JSON **string**, not an object; the governance agent must parse it conceptually.

**Sticky note context:** “Model-Specific Agents …” and “Assess Risk … Assess risk simultaneously.”  
Important nuance: in this workflow, “simultaneously” is conceptual—tools are available; actual parallelism depends on the agent’s tool-calling behavior, not n8n branching.

---

### 2.6 Routing by Risk + Storage
**Overview:** Takes governance results and routes by `riskLevel` into approved vs high-risk storage tables.  
**Nodes involved:** `Route by Risk Level`, `Store Approved Transactions`, `Store High Risk Transactions`

#### Route by Risk Level
- **Type / role:** `n8n-nodes-base.switch`
- **Rules:**
  - **Low Risk**: `riskLevel == "LOW"` OR `"MEDIUM"`
  - **High Risk**: `riskLevel == "HIGH"` OR `"CRITICAL"`
  - Fallback: **Unclassified**
- **Connections:**
  - Low Risk → `Store Approved Transactions`
  - High Risk → `Store High Risk Transactions`
- **Edge cases:**
  - If governance outputs “Requires Review” or other labels, it routes to fallback (but fallback is not connected, so those items stop).

#### Store Approved Transactions
- **Type / role:** `dataTable`
- **Table:** `approved_transactions`
- **Output:** to `Merge Storage Results` (input index 0)
- **Edge cases:** missing table, permission issues.

#### Store High Risk Transactions
- **Type / role:** `dataTable`
- **Table:** `high_risk_transactions`
- **Output:** to `Merge Storage Results` (input index 1)

---

### 2.7 Merge, Aggregate, and Reporting
**Overview:** Combines results from the three storage paths, aggregates items, generates an executive report via Claude, and stores the report.  
**Nodes involved:** `Merge Storage Results`, `Aggregate Results`, `Reporting Agent`, `Anthropic Model - Reporting Agent`, `Reporting Output Parser`, `Store Final Report`

#### Merge Storage Results
- **Type / role:** `n8n-nodes-base.merge`
- **Configuration:** `mode: combine`, `combineBy: position`, `numberInputs: 3`
- **Inputs:**
  - Input 0: from `Store Approved Transactions`
  - Input 1: from `Store High Risk Transactions`
  - Input 2: from `Store Failed Validations`
- **Output:** to `Aggregate Results`
- **Edge cases:**
  - **Combine by position** assumes aligned item ordering and counts across inputs. Here, paths have different cardinalities (some transactions go only to one path), so combined items may be mismatched or missing, and the node may wait for all inputs.
  - If one branch produces 0 items, the merge behavior may yield 0 combined outputs depending on n8n merge semantics; consider “append” mode if you want all items.

#### Aggregate Results
- **Type / role:** `n8n-nodes-base.aggregate`
- **Configuration:** `aggregate: aggregateAllItemData` (collect all items into a single aggregated structure).
- **Output:** to `Reporting Agent`
- **Edge cases:** Large volumes can create huge aggregated payloads, risking LLM context limits.

#### Reporting Agent
- **Type / role:** LangChain agent to produce a structured executive report.
- **Input text:** `{{ JSON.stringify($json) }}` (the aggregated data).
- **System message:** compute totals, approval rate, payouts, tax, net profit, trends, insights, recommendations.
- **Connections:**
  - Model: `Anthropic Model - Reporting Agent`
  - Parser: `Reporting Output Parser`
  - Main output: to `Store Final Report`
- **Edge cases:**
  - Calculations depend on consistent numeric types; earlier steps may store strings (notably tax tool).
  - If aggregated data is not shaped as expected (because merge mis-combined), report may be inaccurate.

#### Anthropic Model - Reporting Agent
- **Type / role:** Claude model.

#### Reporting Output Parser
- **Required:** `executiveSummary`, `totalTransactions`, `totalRevenue`
- **Also:** approval rate, total payouts/taxes, net profit, risk distribution, insights/recommendations.
- **Edge cases:** Schema expects numbers; LLM may output formatted strings.

#### Store Final Report
- **Type / role:** `dataTable`
- **Table:** `monetization_reports`
- **Edge cases:** missing table; consider including run timestamp for traceability.

**Sticky note context:** “Results Reporting … Consolidates validation scores and flags issues.”

---

## 3. Summary Table

| Node Name | Node Type | Functional Role | Input Node(s) | Output Node(s) | Sticky Note |
|---|---|---|---|---|---|
| Schedule Trigger | Schedule Trigger | Time-based workflow entry | — | Workflow Configuration | ## Query Classification<br>**What:** Categorizes incoming requests by complexity and domain.<br>**Why:** Determines optimal routing path and appropriate model selection. |
| Workflow Configuration | Set | Define thresholds/rates constants | Schedule Trigger | Generate Sample Revenue Data | ## Query Classification<br>**What:** Categorizes incoming requests by complexity and domain.<br>**Why:** Determines optimal routing path and appropriate model selection. |
| Generate Sample Revenue Data | Code | Create sample transactions (5 items) | Workflow Configuration | Revenue Signal Agent | ## Query Classification<br>**What:** Categorizes incoming requests by complexity and domain.<br>**Why:** Determines optimal routing path and appropriate model selection. |
| Revenue Signal Agent | LangChain Agent | Validate transaction structure/quality, output status/score | Generate Sample Revenue Data | Route by Validation Status | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Anthropic Model - Revenue Agent | Anthropic Chat Model | LLM backend for validation agent | — (AI model link) | Revenue Signal Agent (ai_languageModel) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Revenue Validation Output Parser | Structured Output Parser | Enforce validation output schema | — (parser link) | Revenue Signal Agent (ai_outputParser) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Route by Validation Status | Switch | Route VALID vs INVALID/SUSPICIOUS | Revenue Signal Agent | Governance Agent; Store Failed Validations | ## Query Classification<br>**What:** Categorizes incoming requests by complexity and domain.<br>**Why:** Determines optimal routing path and appropriate model selection. |
| Store Failed Validations | Data Table | Persist invalid/suspicious validations | Route by Validation Status (Invalid) | Merge Storage Results | ## Results Reporting<br>**What:** Consolidates validation scores and flags issues.<br>**Why:** Provides unified quality metrics for decision-making |
| Governance Agent | LangChain Agent | Orchestrate tools, produce governance decision | Route by Validation Status (Valid) | Route by Risk Level | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Anthropic Model - Governance Agent | Anthropic Chat Model | LLM backend for governance agent | — | Governance Agent (ai_languageModel) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Governance Output Parser | Structured Output Parser | Enforce governance decision schema | — | Governance Agent (ai_outputParser) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Payout Calculation Agent Tool | Agent Tool | Tool: compute payouts via LLM | — | Governance Agent (ai_tool) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Anthropic Model - Payout Tool | Anthropic Chat Model | LLM backend for payout tool | — | Payout Calculation Agent Tool (ai_languageModel) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Payout Output Parser | Structured Output Parser | Enforce payout schema | — | Payout Calculation Agent Tool (ai_outputParser) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Compliance Check Agent Tool | Agent Tool | Tool: compliance check via LLM | — | Governance Agent (ai_tool) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Anthropic Model - Compliance Tool | Anthropic Chat Model | LLM backend for compliance tool | — | Compliance Check Agent Tool (ai_languageModel) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Compliance Output Parser | Structured Output Parser | Enforce compliance schema | — | Compliance Check Agent Tool (ai_outputParser) | ## Model-Specific Agents<br>**What:** Anthropic and OpenAI generate responses based on routing.<br>**Why:** Leverages each model's strengths for optimal performance. |
| Risk Assessment Agent Tool | Agent Tool | Tool: risk scoring via LLM | — | Governance Agent (ai_tool) | ## Assess Risk<br>**What:** Assess risk simultaneously.<br>**Why:** Comprehensive quality assurance |
| Anthropic Model - Risk Tool | Anthropic Chat Model | LLM backend for risk tool | — | Risk Assessment Agent Tool (ai_languageModel) | ## Assess Risk<br>**What:** Assess risk simultaneously.<br>**Why:** Comprehensive quality assurance |
| Risk Output Parser | Structured Output Parser | Enforce risk schema | — | Risk Assessment Agent Tool (ai_outputParser) | ## Assess Risk<br>**What:** Assess risk simultaneously.<br>**Why:** Comprehensive quality assurance |
| Tax Calculation Tool | Code Tool | Tool: deterministic tax computation | — | Governance Agent (ai_tool) | ## Assess Risk<br>**What:** Assess risk simultaneously.<br>**Why:** Comprehensive quality assurance |
| Route by Risk Level | Switch | Route LOW/MEDIUM vs HIGH/CRITICAL | Governance Agent | Store Approved Transactions; Store High Risk Transactions | ## Assess Risk<br>**What:** Assess risk simultaneously.<br>**Why:** Comprehensive quality assurance |
| Store Approved Transactions | Data Table | Persist approved/low-risk items | Route by Risk Level (Low Risk) | Merge Storage Results | ## Assess Risk<br>**What:** Assess risk simultaneously.<br>**Why:** Comprehensive quality assurance |
| Store High Risk Transactions | Data Table | Persist high-risk items | Route by Risk Level (High Risk) | Merge Storage Results | ## Assess Risk<br>**What:** Assess risk simultaneously.<br>**Why:** Comprehensive quality assurance |
| Merge Storage Results | Merge | Combine three storage streams | Store Approved Transactions; Store High Risk Transactions; Store Failed Validations | Aggregate Results | ## Results Reporting<br>**What:** Consolidates validation scores and flags issues.<br>**Why:** Provides unified quality metrics for decision-making |
| Aggregate Results | Aggregate | Aggregate all item data for reporting | Merge Storage Results | Reporting Agent | ## Results Reporting<br>**What:** Consolidates validation scores and flags issues.<br>**Why:** Provides unified quality metrics for decision-making |
| Reporting Agent | LangChain Agent | Create executive monetization report | Aggregate Results | Store Final Report | ## Results Reporting<br>**What:** Consolidates validation scores and flags issues.<br>**Why:** Provides unified quality metrics for decision-making |
| Anthropic Model - Reporting Agent | Anthropic Chat Model | LLM backend for reporting agent | — | Reporting Agent (ai_languageModel) | ## Results Reporting<br>**What:** Consolidates validation scores and flags issues.<br>**Why:** Provides unified quality metrics for decision-making |
| Reporting Output Parser | Structured Output Parser | Enforce reporting schema | — | Reporting Agent (ai_outputParser) | ## Results Reporting<br>**What:** Consolidates validation scores and flags issues.<br>**Why:** Provides unified quality metrics for decision-making |
| Store Final Report | Data Table | Persist final report | Reporting Agent | — | ## Results Reporting<br>**What:** Consolidates validation scores and flags issues.<br>**Why:** Provides unified quality metrics for decision-making |

---

## 4. Reproducing the Workflow from Scratch

1) **Create a new workflow** in n8n named: *Multi-model AI routing & quality assessment system* (or your preferred name).

2) **Add Trigger**
   - Add **Schedule Trigger**.
   - Set it to run daily at **09:00** (or adjust to your needs).

3) **Add configuration constants**
   - Add a **Set** node named **Workflow Configuration**.
   - Add fields (keep “Include Other Fields” enabled):
     - `revenueThreshold` (Number) = `10000`
     - `highRiskThreshold` (Number) = `50000`
     - `complianceRegion` (String) = `US`
     - `taxRate` (Number) = `0.21`
     - `payoutCommissionRate` (Number) = `0.15`
   - Connect: **Schedule Trigger → Workflow Configuration**.

4) **Generate (or ingest) transactions**
   - Add a **Code** node named **Generate Sample Revenue Data**.
   - Paste JS that returns multiple items (one per transaction). (In production, replace with your data source node.)
   - Connect: **Workflow Configuration → Generate Sample Revenue Data**.
   - Important: If you need the config fields downstream, modify the code node to copy them into each transaction item or use Merge/Item Lists accordingly.

5) **Revenue validation agent**
   - Add **AI Agent (LangChain)** node named **Revenue Signal Agent**.
   - Set **Text** to: `{{ JSON.stringify($json) }}`
   - Set **Prompt type** to “Define” and use the provided system message (validation instructions).
   - Enable **Structured Output** (output parser).
   - Add **Anthropic Chat Model** node named **Anthropic Model - Revenue Agent**:
     - Choose model: `claude-sonnet-4-5-20250929` (or an available Sonnet equivalent).
     - Configure **Anthropic API credentials** in n8n Credentials and select them in the node.
   - Add **Structured Output Parser** node named **Revenue Validation Output Parser**:
     - Schema type: Manual
     - Paste the validation schema (transactionId, validationStatus, score, anomalies, reasoning, originalData).
   - Wire AI connections:
     - Revenue Signal Agent `ai_languageModel` → Anthropic Model - Revenue Agent
     - Revenue Signal Agent `ai_outputParser` → Revenue Validation Output Parser
   - Main connection: **Generate Sample Revenue Data → Revenue Signal Agent**.

6) **Route by validation status**
   - Add a **Switch** node named **Route by Validation Status**.
   - Add outputs:
     - “Valid”: `{{$json.validationStatus}} equals "VALID"`
     - “Invalid”: `equals "INVALID"` OR `equals "SUSPICIOUS"`
     - Fallback renamed “Unprocessed”
   - Connect: **Revenue Signal Agent → Route by Validation Status**.

7) **Store failed validations**
   - Add **Data Table** node named **Store Failed Validations**.
   - Select/enter Data Table name: `failed_validations` (create it in n8n Data Tables if needed).
   - Connect: **Route by Validation Status (Invalid) → Store Failed Validations**.

8) **Governance agent**
   - Add **AI Agent (LangChain)** node named **Governance Agent**.
   - Text: `{{ JSON.stringify($json) }}`
   - System message: governance orchestration instructions (call payout/compliance/risk/tax tools, then summarize).
   - Enable structured output.
   - Add **Anthropic Chat Model** named **Anthropic Model - Governance Agent** and select the same Claude model + credentials.
   - Add **Structured Output Parser** named **Governance Output Parser** and paste governance schema (transactionId, payoutAmount, taxLiability, complianceStatus, riskLevel, etc.).
   - Connect AI links:
     - Governance Agent `ai_languageModel` → Anthropic Model - Governance Agent
     - Governance Agent `ai_outputParser` → Governance Output Parser
   - Connect main: **Route by Validation Status (Valid) → Governance Agent**.

9) **Add governance tools (callable by the Governance Agent)**
   - **Payout Tool**
     - Add **Agent Tool** named **Payout Calculation Agent Tool**.
     - Tool input text: `{{ $fromAI("revenueData", "...", "json") }}`
     - Add **Anthropic Model** node **Anthropic Model - Payout Tool** + credentials.
     - Add **Structured Output Parser** node **Payout Output Parser** with payout schema.
     - Wire: Payout Tool `ai_languageModel` → Anthropic Model - Payout Tool; Payout Tool `ai_outputParser` → Payout Output Parser.
     - Wire tool to governance: Payout Tool `ai_tool` → Governance Agent.
   - **Compliance Tool**
     - Add **Agent Tool** named **Compliance Check Agent Tool**.
     - Input: `{{ $fromAI("transactionData", "...", "json") }}`
     - Add model **Anthropic Model - Compliance Tool**, plus **Compliance Output Parser**.
     - Wire model/parser and connect `ai_tool` → Governance Agent.
   - **Risk Tool**
     - Add **Agent Tool** named **Risk Assessment Agent Tool**.
     - Input: `{{ $fromAI("transactionData", "...", "json") }}`
     - Add model **Anthropic Model - Risk Tool**, plus **Risk Output Parser**.
     - Wire model/parser and connect `ai_tool` → Governance Agent.
   - **Tax Code Tool**
     - Add **Code Tool** node (LangChain Tool Code) named **Tax Calculation Tool**.
     - Use code that reads `$fromAI('revenueData', ..., 'json')`, computes region-based taxes, and returns JSON.
     - Connect `ai_tool` → Governance Agent.

   **Important setup constraint:** The Governance Agent must provide tool arguments matching `revenueData` and `transactionData`. If tool calls fail, adjust the governance agent prompt to explicitly pass the full transaction object under both keys, or standardize tool inputs to a single key.

10) **Route by risk level**
   - Add **Switch** node named **Route by Risk Level**.
   - Outputs:
     - Low Risk: `riskLevel == "LOW"` OR `"MEDIUM"`
     - High Risk: `riskLevel == "HIGH"` OR `"CRITICAL"`
     - Fallback “Unclassified”
   - Connect: **Governance Agent → Route by Risk Level**.

11) **Store routed results**
   - Add **Data Table** node **Store Approved Transactions** → table `approved_transactions`.
   - Add **Data Table** node **Store High Risk Transactions** → table `high_risk_transactions`.
   - Connect:
     - Route by Risk Level (Low Risk) → Store Approved Transactions
     - Route by Risk Level (High Risk) → Store High Risk Transactions

12) **Merge storage outputs**
   - Add **Merge** node named **Merge Storage Results**.
   - Mode: **Combine**, Combine By: **Position**, Number of inputs: **3**.
   - Connect:
     - Store Approved Transactions → Merge (Input 1 / index 0)
     - Store High Risk Transactions → Merge (Input 2 / index 1)
     - Store Failed Validations → Merge (Input 3 / index 2)

   **Recommended adjustment (production):** use “Append” instead of “Combine by position” unless you guarantee aligned item counts.

13) **Aggregate**
   - Add **Aggregate** node named **Aggregate Results**.
   - Aggregation: **Aggregate All Item Data**.
   - Connect: **Merge Storage Results → Aggregate Results**.

14) **Reporting**
   - Add **AI Agent** named **Reporting Agent**.
   - Text: `{{ JSON.stringify($json) }}`
   - System message: reporting instructions (executive summary, totals, approval rate, risk distribution, etc.).
   - Add **Anthropic Model - Reporting Agent** and **Reporting Output Parser** with the report schema.
   - Connect:
     - Aggregate Results → Reporting Agent
     - Reporting Agent → Store Final Report

15) **Store final report**
   - Add **Data Table** node named **Store Final Report**.
   - Table: `monetization_reports`.

---

## 5. General Notes & Resources

| Note Content | Context or Link |
|---|---|
| Active API accounts for Anthropic Claude and OpenAI are mentioned as prerequisites, but this workflow JSON contains **Anthropic nodes only** (no OpenAI integration present). | Sticky note “Prerequisites” |
| Setup steps mention Google Sheets, Slack/Gmail notifications; this workflow uses **n8n Data Tables** and includes **no** Google Sheets/Slack/Gmail nodes. | Sticky note “Setup Steps” |
| “Reduces AI costs by 40–60% through intelligent model selection” is stated, but model routing between Anthropic/OpenAI is not implemented in the nodes provided. | Sticky note “Benefits” |
| If you need true “multi-model routing”, add an OpenAI Chat Model node and a router (Switch/IF) based on complexity score, then connect the selected model to the agent(s). | Derived from sticky notes vs actual implementation |
| Risk and compliance region tax logic currently mismatches transaction regions (“Europe”, “North America”, etc.) vs tax tool region keys (“EU”, “US”, “UK”, “APAC”). Normalize region values early to avoid default tax rates being applied unintentionally. | Workflow behavior note |

